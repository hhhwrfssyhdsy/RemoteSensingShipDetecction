{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-24T13:23:26.703890Z",
     "iopub.status.busy": "2025-09-24T13:23:26.703703Z",
     "iopub.status.idle": "2025-09-24T13:23:35.010155Z",
     "shell.execute_reply": "2025-09-24T13:23:35.009509Z",
     "shell.execute_reply.started": "2025-09-24T13:23:26.703873Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-24T13:24:35.355743Z",
     "iopub.status.busy": "2025-09-24T13:24:35.355460Z",
     "iopub.status.idle": "2025-09-24T13:24:35.359896Z",
     "shell.execute_reply": "2025-09-24T13:24:35.359383Z",
     "shell.execute_reply.started": "2025-09-24T13:24:35.355721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#SSDD数据路径读取\n",
    "SSDD_train_inshore_img_path = r\"/kaggle/input/ship-detect-private/SSDD/SSDD/JPEGImages_train_inshore\"\n",
    "SSDD_train_offshore_img_path = r\"/kaggle/input/ship-detect-private/SSDD/SSDD/JPEGImages_train_offshore\"\n",
    "SSDD_test_inshore_img_path = r\"/kaggle/input/ship-detect-private/SSDD/SSDD/JPEGImages_test_inshore\"\n",
    "SSDD_test_offshore_img_path = r\"/kaggle/input/ship-detect-private/SSDD/SSDD/JPEGImages_test_offshore\"\n",
    "SSDD_train_label_path = r\"/kaggle/input/ship-detect-private/SSDD_labels/SSDD_labels/train_labels\"\n",
    "SSDD_test_inshore_label_path = r\"/kaggle/input/ship-detect-private/SSDD_labels/SSDD_labels/test_inshore_labels\"\n",
    "SSDD_test_offshore_label_path = r\"/kaggle/input/ship-detect-private/SSDD_labels/SSDD_labels/test_offshore_labels\"\n",
    "#SeaShip数据读取\n",
    "S_img_path = r\"/kaggle/input/ship-detect-private/SeaShips(7000)/JPEGImages\"\n",
    "S_label_path = r\"/kaggle/input/ship-detect-private/SeaShips_labels/SeaShips_labels/labels\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch的Dataset数据集类构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class YOLODataset(Dataset):\n",
    "    def __init__(self, img_paths, label_paths, transform=None, target_size=640):\n",
    "        \"\"\"\n",
    "        初始化YOLO数据集\n",
    "        \n",
    "        Args:\n",
    "            img_paths: 图像路径列表，可以是单个路径或路径列表\n",
    "            label_paths: 标签路径列表，可以是单个路径或路径列表\n",
    "            transform: 图像变换\n",
    "            target_size: 目标图像尺寸\n",
    "        \"\"\"\n",
    "        self.img_paths = []\n",
    "        self.label_paths = []\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # 处理多个路径输入\n",
    "        if isinstance(img_paths, str):\n",
    "            img_paths = [img_paths]\n",
    "        if isinstance(label_paths, str):\n",
    "            label_paths = [label_paths]\n",
    "        \n",
    "        # 收集所有图像和标签文件路径\n",
    "        for img_path, label_path in zip(img_paths, label_paths):\n",
    "            if os.path.exists(img_path) and os.path.exists(label_path):\n",
    "                img_files = [f for f in os.listdir(img_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                for img_file in img_files:\n",
    "                    name_without_ext = os.path.splitext(img_file)[0]\n",
    "                    label_file = os.path.join(label_path, name_without_ext + '.txt')\n",
    "                    \n",
    "                    if os.path.exists(label_file):\n",
    "                        self.img_paths.append(os.path.join(img_path, img_file))\n",
    "                        self.label_paths.append(label_file)\n",
    "        \n",
    "        print(f\"Loaded {len(self.img_paths)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 读取图像\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        original_size = image.size  # (width, height)\n",
    "        \n",
    "        # 读取标签\n",
    "        label_path = self.label_paths[idx]\n",
    "        boxes, labels = self.parse_yolo_label(label_path, original_size)\n",
    "        \n",
    "        # 应用变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # 默认转换\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize((self.target_size, self.target_size)),\n",
    "                transforms.ToTensor(),\n",
    "            ])\n",
    "            image = transform(image)\n",
    "        \n",
    "        # 调整边界框到目标尺寸\n",
    "        scale_x = self.target_size / original_size[0]\n",
    "        scale_y = self.target_size / original_size[1]\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            boxes[:, [0, 2]] *= scale_x  # x坐标缩放\n",
    "            boxes[:, [1, 3]] *= scale_y  # y坐标缩放\n",
    "        \n",
    "        # 转换为tensor\n",
    "        boxes = torch.FloatTensor(boxes) if len(boxes) > 0 else torch.zeros((0, 4))\n",
    "        labels = torch.LongTensor(labels) if len(labels) > 0 else torch.zeros((0,))\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx]),\n",
    "            'area': (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) if len(boxes) > 0 else torch.zeros((0,)),\n",
    "            'iscrowd': torch.zeros((len(labels),), dtype=torch.int64)\n",
    "        }\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "    def parse_yolo_label(self, label_path, image_size):\n",
    "        \"\"\"\n",
    "        解析YOLO格式的标签文件\n",
    "        \n",
    "        Args:\n",
    "            label_path: 标签文件路径\n",
    "            image_size: 图像尺寸 (width, height)\n",
    "            \n",
    "        Returns:\n",
    "            boxes: 边界框 [x_min, y_min, x_max, y_max]\n",
    "            labels: 类别标签\n",
    "        \"\"\"\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                data = line.strip().split()\n",
    "                if len(data) >= 5:\n",
    "                    class_id = int(data[0])\n",
    "                    x_center = float(data[1])\n",
    "                    y_center = float(data[2])\n",
    "                    width = float(data[3])\n",
    "                    height = float(data[4])\n",
    "                    \n",
    "                    # 转换为绝对坐标\n",
    "                    x_center_abs = x_center * image_size[0]\n",
    "                    y_center_abs = y_center * image_size[1]\n",
    "                    width_abs = width * image_size[0]\n",
    "                    height_abs = height * image_size[1]\n",
    "                    \n",
    "                    # 计算边界框坐标 [x_min, y_min, x_max, y_max]\n",
    "                    x_min = x_center_abs - width_abs / 2\n",
    "                    y_min = y_center_abs - height_abs / 2\n",
    "                    x_max = x_center_abs + width_abs / 2\n",
    "                    y_max = y_center_abs + height_abs / 2\n",
    "                    \n",
    "                    boxes.append([x_min, y_min, x_max, y_max])\n",
    "                    labels.append(class_id)\n",
    "        \n",
    "        return np.array(boxes), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建数据集实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 数据增强变换\n",
    "def get_train_transforms(target_size=640):\n",
    "    \"\"\"训练时的数据增强变换\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((target_size, target_size)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_transforms(target_size=640):\n",
    "    \"\"\"验证时的变换（无数据增强）\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((target_size, target_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# 创建数据集\n",
    "def create_datasets(target_size=640):\n",
    "    \"\"\"\n",
    "    创建训练和验证数据集\n",
    "    \"\"\"\n",
    "    # 获取变换\n",
    "    train_transform = get_train_transforms(target_size)\n",
    "    val_transform = get_val_transforms(target_size)\n",
    "    \n",
    "    # 创建SSDD训练数据集\n",
    "    ssdd_train_img_paths = [\n",
    "        SSDD_train_inshore_img_path,\n",
    "        SSDD_train_offshore_img_path\n",
    "    ]\n",
    "    \n",
    "    ssdd_train_label_paths = [\n",
    "        SSDD_train_label_path,\n",
    "        SSDD_train_label_path\n",
    "    ]\n",
    "    \n",
    "    ssdd_train_dataset = YOLODataset(\n",
    "        img_paths=ssdd_train_img_paths,\n",
    "        label_paths=ssdd_train_label_paths,\n",
    "        transform=train_transform,\n",
    "        target_size=target_size\n",
    "    )\n",
    "    \n",
    "    # 创建SeaShip数据集\n",
    "    seaship_dataset = YOLODataset(\n",
    "        img_paths=S_img_path,\n",
    "        label_paths=S_label_path,\n",
    "        transform=train_transform,\n",
    "        target_size=target_size\n",
    "    )\n",
    "    \n",
    "    # 合并数据集\n",
    "    combined_train_dataset = ConcatDataset([ssdd_train_dataset, seaship_dataset])\n",
    "    \n",
    "    # 创建验证数据集（使用SSDD测试集）\n",
    "    ssdd_val_img_paths = [\n",
    "        SSDD_test_inshore_img_path,\n",
    "        SSDD_test_offshore_img_path\n",
    "    ]\n",
    "    \n",
    "    ssdd_val_label_paths = [\n",
    "        SSDD_test_inshore_label_path,\n",
    "        SSDD_test_offshore_label_path\n",
    "    ]\n",
    "    \n",
    "    val_dataset = YOLODataset(\n",
    "        img_paths=ssdd_val_img_paths,\n",
    "        label_paths=ssdd_val_label_paths,\n",
    "        transform=val_transform,\n",
    "        target_size=target_size\n",
    "    )\n",
    "    \n",
    "    return combined_train_dataset, val_dataset\n",
    "\n",
    "# 自定义collate函数用于批处理\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    自定义批处理函数，处理不同数量的目标\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    targets = []\n",
    "    \n",
    "    for img, target in batch:\n",
    "        images.append(img)\n",
    "        targets.append(target)\n",
    "    \n",
    "    images = torch.stack(images, 0)\n",
    "    return images, targets\n",
    "\n",
    "# 创建数据加载器\n",
    "def create_dataloaders(batch_size=16, num_workers=4, target_size=640):\n",
    "    \"\"\"\n",
    "    创建训练和验证数据加载器\n",
    "    \"\"\"\n",
    "    train_dataset, val_dataset = create_datasets(target_size)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  构建diffusion模型(待完成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建DCGAN网络(待完成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline的基础上进行finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8321987,
     "sourceId": 13159010,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
